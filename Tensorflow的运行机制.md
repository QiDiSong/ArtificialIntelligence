## TensorFlow 为什么要构建计算图 Graph ？

> 为了在Python中进行高效的数值计算,我们通常会使用像NumPy一类的库,将一些诸如矩阵乘法的耗时操作**在Python环境的外部来计算,这些计算通常会通过其它语言并用*更为高效的代码*来实现**。
>
> **但遗憾的是,每一个操作切换回Python环境时仍需要不小的开销。**如果你想在GPU或者分布式环境中计算时,这一开销更加可怖,这一开销主要可能是用来进行数据迁移。
>
> TensorFlow也是在Python外部完成其主要工作,但是进行了改进以避免这种开销。其并没有采用在Python外部独立运行某个耗时操作的方式,而是**先让我们描述一个交互操作图,然后完全将其运行在Python外部**。这与Theano或Torch的做法类似。
>
> **因此Python代码的目的是用来构建这个可以在外部运行的计算图,以及安排计算图的哪一部分应该被运行。**

**TensorFlow 的总体机制是什么？**

> TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得零或多个 tensor , 执行计算, 产生零或多个 tensor . 每个 tensor 是一个***类型化的多维数组***. 例如, 你可以将一小组图像集表示为一个**四维浮点数数组**, 这四个维度分别是 [ batch_size, height, width, channel ] .
>
> **一个 TensorFlow 的计算图描述了计算的过程. 为了进行计算, 图必须在 session 里被启动. session 将图的 op 分发到诸如 CPU 或 GPU 之类的设备上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy 的 ndarray 对象;** 在 C 和 C++ 语言中, 返回的 tensor 是 tensorflow::Tensor 的实例.





**TensorFlow 的设计机制会对我写的程序结构造成什么影响？**

> 因为它的这种独特的设计机制，所以我们的程序也会相应的表现出适应它的独特的**二段式结构**，而不是通常程序的**线性结构.**
>
> TensorFlow 程序通常被组织成一个**构建阶段**和一个**执行阶段**. <u>在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.</u>
>
> 例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op.





**进一步的 TensorFlow 的设计架构是什么样的？**

找到一幅比较好的架构图：

![img](https://pic4.zhimg.com/80/v2-607695837c0ec16aeea0caed21bc0b57_720w.jpg)

可以看到，TensorFlow 整体架构还是比较复杂的，但是我们只需要大致了解几个层的作用：

- 前端的实现层，它就是我们构建计算图的主要工具，有 Python 和 C++等接口
- C API 是前端到后端的桥梁
- 分布式任务层负责分解计算图 Graph，派发和收集数据
- `Kernel`层是`OP`在某种硬件设备的特定实现，它负责执行`OP`的运算
- 网络层负责多设备之间通信任务的处理
- 设备层就是类似 cuDNN 的专门在 GPU之类的特定设备上进行特定数值计算的框架
